import cv2
import numpy as np
from ultralytics import YOLO
from deep_sort_realtime.deepsort_tracker import DeepSort

# 1ï¸âƒ£ åŠ è½½ YOLO æ¨¡å‹
model = YOLO("runs/train/exp_optimized5/weights/best.pt")  # ä½ çš„YOLOæ¨¡å‹è·¯å¾„

# 2ï¸âƒ£ åˆå§‹åŒ– DeepSORT è·Ÿè¸ªå™¨ï¼ˆä¼˜åŒ–å‚æ•°ï¼‰
tracker = DeepSort(
    max_cosine_distance=0.5,  # å…è®¸æ›´å¤§ç›¸ä¼¼åº¦ï¼Œå‡å°‘é‡å¤è®¡æ•°
    nn_budget=200,            # å…è®¸æ›´å¤§çš„ ReID æ¨¡å‹
    max_age=50,               # å…è®¸ç›®æ ‡æ¶ˆå¤± 50 å¸§åä»æ¢å¤ ID
    n_init=5,                 # éœ€è¦ 5 å¸§è¿ç»­æ£€æµ‹åç¡®è®¤ç›®æ ‡ï¼ˆå‡å°‘è¯¯æ£€ï¼‰
    embedder="mobilenet",     # ä½¿ç”¨ MobileNet ä½œä¸ºç‰¹å¾æå–å™¨
    embedder_gpu=True         # å¯ç”¨ GPU åŠ é€Ÿ
)

# 3ï¸âƒ£ è¯»å–è§†é¢‘æ–‡ä»¶
video_path = "test4.mp4"
cap = cv2.VideoCapture(video_path)

# 4ï¸âƒ£ åˆå§‹åŒ–è§†é¢‘å†™å…¥
fps = int(cap.get(cv2.CAP_PROP_FPS))
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))

out = cv2.VideoWriter("output2.mp4", cv2.VideoWriter_fourcc(*"mp4v"), fps, (width, height))

# 5ï¸âƒ£ YOLO æ£€æµ‹è½¬æ¢ä¸º DeepSORT æ ¼å¼
def yolo_to_detections(results):
    detections = []
    for result in results:
        for box in result.boxes:
            x1, y1, x2, y2 = map(int, box.xyxy[0])  # ç›®æ ‡æ¡†åæ ‡
            w, h = x2 - x1, y2 - y1
            conf = box.conf[0].item()  # ç½®ä¿¡åº¦
            cls = int(box.cls[0])  # ç±»åˆ«ç´¢å¼•

            if conf > 0.4:  # åªè·Ÿè¸ªç½®ä¿¡åº¦ > 0.4 çš„ç›®æ ‡
                detections.append(([x1, y1, w, h], conf, cls))

    return detections

# 6ï¸âƒ£ é€å¸§å¤„ç†è§†é¢‘
while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    # ğŸŸ¢ (a) è¿è¡Œ YOLO æ£€æµ‹
    results = model.predict(frame, conf=0.4)  # ç½®ä¿¡åº¦é˜ˆå€¼æé«˜åˆ° 0.4
    dets_list = yolo_to_detections(results)

    # ğŸ”µ (b) æ›´æ–° DeepSORT ç›®æ ‡è·Ÿè¸ª
    tracks = tracker.update_tracks(dets_list, frame=frame) if dets_list else []

    # ğŸ”´ (c) å¯è§†åŒ–è·Ÿè¸ªç»“æœ
    for track in tracks:
        if not track.is_confirmed():
            continue
        track_id = track.track_id
        x, y, w, h = map(int, track.to_ltwh())  # è·å–è·Ÿè¸ªç›®æ ‡çš„åæ ‡

        # ç»˜åˆ¶ç›®æ ‡æ¡†
        cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)
        label = f"ID: {track_id}"
        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)

    # ğŸŸ¡ (d) å†™å…¥å¤„ç†åçš„è§†é¢‘å¸§
    out.write(frame)

# 7ï¸âƒ£ é‡Šæ”¾èµ„æº
cap.release()
out.release()
cv2.destroyAllWindows()
print("ğŸ‰ å¤„ç†å®Œæˆï¼Œè§†é¢‘å·²ä¿å­˜ä¸º output.mp4")
